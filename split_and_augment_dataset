import os
import random
import shutil
from glob import glob
from PIL import Image
from tqdm import tqdm
from torchvision import transforms
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ============================================================
# 1Augmentazione opzionale
# ============================================================
class AdvancedAugment:
    def __init__(self):
        self.transform = transforms.Compose([
            transforms.RandomResizedCrop(128, scale=(0.9, 1.0)),
            transforms.RandomHorizontalFlip(),
            transforms.RandomVerticalFlip(),
            transforms.ColorJitter(brightness=0.2, contrast=0.2),
            transforms.RandomRotation(10),
        ])

    def __call__(self, img):
        return self.transform(img)


AUGMENT = AdvancedAugment()


# ============================================================
# Divisione in train / val / test (solo ROI)
# ============================================================
def split_dataset(class_names, source_dir, output_dir, split_ratio, augment = False):
    print(" Divisione in train / val / test...")
    train_ratio, val_ratio, test_ratio = split_ratio

    # Crea struttura di cartelle
    for split in ["train", "val", "test"]:
        for cls in class_names:
            os.makedirs(os.path.join(output_dir, split, cls), exist_ok=True)

    # Divisione e copia file
    for cls in class_names:
        # Considera solo immagini ROI
        images = sorted(glob(os.path.join(source_dir, cls, "*_roi.jpg")))
        random.shuffle(images)

        n_total = len(images)
        n_train = int(n_total * train_ratio)
        n_val = int(n_total * val_ratio)

        splits = {
            "train": images[:n_train],
            "val": images[n_train:n_train + n_val],
            "test": images[n_train + n_val:]
        }

        for split_name, imgs in splits.items():
            for img_path in tqdm(imgs, desc=f"{cls} â†’ {split_name}"):
                dst_folder = os.path.join(output_dir, split_name, cls)

                # Copia solo la ROI
                shutil.copy(img_path, dst_folder)

        print(f"{cls}: {n_train} train / {n_val} val / {n_total - n_train - n_val} test")

    print("\nDivisione completata.")


    # Se richiesto â†’ esegue augmentation solo sul training
    if augment:
        visual_smote(os.path.join(output_dir, "train"))

    print(f"ðŸ“‚ Dataset salvato in: {output_dir}")


# ============================================================
# Augmentation dati
# ============================================================
def visual_smote(train_dir):
    
    print("\n Bilanciamento visivo (Visual SMOTE)...")

    class_counts = {cls: len(glob(os.path.join(train_dir, cls, "*_roi.jpg"))) for cls in CLASSES}
    target = max(class_counts.values())

    print(f"Immagini per classe prima: {class_counts}")
    print(f"Target per classe: {target}")

    for cls in CLASSES:
        folder = os.path.join(train_dir, cls)
        images = sorted(glob(os.path.join(folder, "*_roi.jpg")))
        count = len(images)

        if count < target:
            needed = target - count
            print(f"Genero {needed} immagini per {cls}...")

            for i in tqdm(range(needed), desc=f"Augment {cls}"):
                src_img = random.choice(images)
                img = Image.open(src_img).convert("RGB")
                img_aug = AUGMENT(img)

                new_img_name = os.path.basename(src_img).replace("_roi.jpg", f"_aug{i}_roi.jpg")
                img_aug.save(os.path.join(folder, new_img_name))

    print("\nBilanciamento completato.")
    final_counts = {cls: len(glob(os.path.join(train_dir, cls, "*_roi.jpg"))) for cls in CLASSES}
    print(f"Dopo bilanciamento: {final_counts}")



if __name__ == "__main__":
    # ============================================================
    # CONFIGURAZIONE
    # ============================================================
    CLASSES = ["G1", "G2", "NEG"]

    # Cartella di origine (con ROI + maschere)
    SOURCE_DIR = "/Users/saracurti/Desktop/images_cropped"

    # Cartella di output (dataset finale)
    AUGMENTED = False  # Se True esegue augmentation sui dati di training
    if AUGMENTED:
        OUTPUT_DIR = "/Users/saracurti/Desktop/images_split_and_augmented"
    else:
        OUTPUT_DIR = "/Users/saracurti/Desktop/images_split_only"

    # Rapporto di divisione: train / val / test
    SPLIT_RATIOS = (0.80, 0.10, 0.10)
    
    random.seed(42)
    # Step : dividi in train / val / test
    split_dataset(class_names=CLASSES, source_dir=SOURCE_DIR, output_dir=OUTPUT_DIR, 
                  split_ratio=SPLIT_RATIOS, augment=AUGMENTED) #augment mi dice se aumentare dati
    


    import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader

# ============================================================
# ðŸ“Š Calcolo mean e std solo sul training set
# ============================================================
def compute_mean_std(train_dir, batch_size=64):
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])

    dataset = datasets.ImageFolder(train_dir, transform=transform)
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

    mean = 0.
    std = 0.
    total_images = 0

    for images, _ in loader:
        batch_samples = images.size(0)  # numero immagini nel batch
        images = images.view(batch_samples, images.size(1), -1)  # (batch, 3, H*W)
        mean += images.mean(2).sum(0)
        std += images.std(2).sum(0)
        total_images += batch_samples

    mean /= total_images
    std /= total_images

    print(f"\nðŸ“Š Mean: {mean}")
    print(f"ðŸ“Š Std:  {std}")

    # Se vuoi salvare su file per usarle dopo:
    with open(os.path.join(train_dir, "../normalization.txt"), "w") as f:
        f.write(f"mean: {mean.tolist()}\n")
        f.write(f"std: {std.tolist()}\n")

    return mean, std


TRAIN_DIR = "/Users/saracurti/Desktop/images_split_only/train"  # percorso al train set--> cambia a secondo del tipo di dati che voglio
mean, std = compute_mean_std(TRAIN_DIR)

#Caso augmented:
#  Mean: tensor([0.3392, 0.2624, 0.2732])
# Std:  tensor([0.3357, 0.2673, 0.2778])

# Caso solo split:
# Mean: tensor([0.3307, 0.2558, 0.2671])
# Std:  tensor([0.3395, 0.2707, 0.2822])
